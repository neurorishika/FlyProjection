{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs Available:\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "Setting memory growth for GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Cameras Available:\n",
      "a2A2448-105g5m_40490701\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pypylon import pylon\n",
    "from basler_camera import BaslerCamera, list_basler_cameras\n",
    "import subprocess as sp\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "\n",
    "def get_gpu_memory():\n",
    "    command = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "    memory_free_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "    return memory_free_values\n",
    "\n",
    "# dont use gpu\n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "# Set GPU memory growth\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPUs Available:\")\n",
    "for gpu in gpus:\n",
    "    print(gpu)\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      print(\"Setting memory growth for GPU:\", gpu)\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "# list available cameras\n",
    "print(\"Cameras Available:\")\n",
    "cameras = list_basler_cameras()\n",
    "\n",
    "\n",
    "# Acquisition Parameters\n",
    "EXPOSURE_TIME, GAIN, CAMERA_FORMAT, WIDTH, HEIGHT, OFFSETX, OFFSETY = 10000, 30, \"Mono8\", 2048, 2048, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigger mode set to Continuous. FPS will be ignored.\n",
      "Getting camera...\n",
      "a2A2448-105g5m_40490701\n",
      "Found 1 cameras.\n",
      "Camera a2A2448-105g5m_40490701 selected.\n",
      "Registered continuous acquisition configuration.\n",
      "MaxNumBuffer set to 763200. Acquisitions will be limited to 2 hours. To change, modify the code.\n",
      "Camera initialized.\n",
      "Exposure time set to 10000 microseconds.\n",
      "Gain set to 30 dB.\n",
      "Set width to 2048, height to 2048, offset to (0, 0).\n",
      "Camera initialized.\n"
     ]
    }
   ],
   "source": [
    "# get a single image from the camera\n",
    "with BaslerCamera(\n",
    "    index=0,\n",
    "    FPS=100,\n",
    "    EXPOSURE_TIME=EXPOSURE_TIME,\n",
    "    GAIN=GAIN,\n",
    "    WIDTH=WIDTH,\n",
    "    HEIGHT=HEIGHT,\n",
    "    OFFSETX=OFFSETX,\n",
    "    OFFSETY=OFFSETY,\n",
    "    TRIGGER_MODE=\"Continuous\",\n",
    "    CAMERA_FORMAT=CAMERA_FORMAT,\n",
    "    record_video=False,\n",
    "    video_output_path=None,\n",
    "    video_output_name=None,\n",
    "    lossless=True,\n",
    "    debug=False,\n",
    ") as camera:\n",
    "    camera.start()\n",
    "    image = camera.get_array()\n",
    "    camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 1024, 1024, 32)    320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 512, 512, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 512, 512, 64)      18496     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 512, 512, 64)      36928     \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 1024, 1024, 64)   0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 1024, 1024, 32)    18464     \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 1024, 1024, 1)     289       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74,497\n",
      "Trainable params: 74,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(4, 1024, 1024, 1)\n"
     ]
    }
   ],
   "source": [
    "# create a random convolutional neural network for testing\n",
    "\n",
    "# create a unet model\n",
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        # Encoder\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(WIDTH//2, HEIGHT//2, 1)),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        \n",
    "        # Decoder\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.UpSampling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# compile the model\n",
    "model.compile(\n",
    "    optimizer='adam', # optimizer\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), # loss function\n",
    "    metrics=['accuracy'] # metrics\n",
    ")\n",
    "\n",
    "# print model summary\n",
    "model.summary()\n",
    "\n",
    "# break image into 4 quadrants to create a batch of 4 images\n",
    "image_ = image.reshape(1, WIDTH, HEIGHT, 1)\n",
    "image_ = np.concatenate([image_[:, :WIDTH//2, :HEIGHT//2], image_[:, WIDTH//2:, :HEIGHT//2], image_[:, :WIDTH//2, HEIGHT//2:], image_[:, WIDTH//2:, HEIGHT//2:]], axis=0)\n",
    "print(image_.shape)\n",
    "\n",
    "predictions = model.predict(image_).squeeze()\n",
    "\n",
    "# plot the image and the predictions\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].set_title(\"Image\")\n",
    "ax[0].axis('off')\n",
    "# reconstruct the image\n",
    "predictions = np.concatenate([\n",
    "    np.concatenate([predictions[0], predictions[2]], axis=1),\n",
    "    np.concatenate([predictions[1], predictions[3]], axis=1)\n",
    "], axis=0)\n",
    "ax[1].imshow(predictions, cmap='gray')\n",
    "ax[1].set_title(\"Predictions\")\n",
    "ax[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigger mode set to Continuous. FPS will be ignored.\n",
      "Getting camera...\n",
      "a2A2448-105g5m_40490701\n",
      "Found 1 cameras.\n",
      "Camera a2A2448-105g5m_40490701 selected.\n",
      "Registered continuous acquisition configuration.\n",
      "MaxNumBuffer set to 763200. Acquisitions will be limited to 2 hours. To change, modify the code.\n",
      "Camera initialized.\n",
      "Exposure time set to 10000 microseconds.\n",
      "Gain set to 30 dB.\n",
      "Set width to 2048, height to 2048, offset to (0, 0).\n",
      "Camera initialized.\n"
     ]
    }
   ],
   "source": [
    "# create an acquisition + prediction loop\n",
    "\n",
    "update_period = 1 # seconds\n",
    "\n",
    "previous_time = time.perf_counter()\n",
    "last_display = time.perf_counter() - 1.1*update_period\n",
    "\n",
    "fps = []\n",
    "\n",
    "# setup live frame rate and gpu memory plot\n",
    "%matplotlib qt\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12,3))\n",
    "ax.set_title(\"Resource Usage\")\n",
    "ax.set_xlabel(\"Frame\")\n",
    "ax.set_ylabel(\"FPS (Hz)\", color='k')\n",
    "ax.grid()\n",
    "line1, = ax.plot([], [], 'k-')\n",
    "plt.tight_layout()\n",
    "plt.ion()\n",
    "plt.show()\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# WARM UP THE GPU\n",
    "start_time = time.perf_counter()\n",
    "while time.perf_counter() - start_time < 10:\n",
    "    image = np.random.rand(1, WIDTH//2, HEIGHT//2, 1)\n",
    "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "    image = tf.repeat(image, BATCH_SIZE, axis=0)\n",
    "    predictions = model.predict(image, verbose=0)\n",
    "\n",
    "# dont use the gpu for this\n",
    "with BaslerCamera(\n",
    "    index=0,\n",
    "    FPS=100,\n",
    "    EXPOSURE_TIME=EXPOSURE_TIME,\n",
    "    GAIN=GAIN,\n",
    "    WIDTH=WIDTH,\n",
    "    HEIGHT=HEIGHT,\n",
    "    OFFSETX=OFFSETX,\n",
    "    OFFSETY=OFFSETY,\n",
    "    TRIGGER_MODE=\"Continuous\",\n",
    "    CAMERA_FORMAT=CAMERA_FORMAT,\n",
    "    record_video=False,\n",
    "    video_output_path=None,\n",
    "    video_output_name=None,\n",
    "    lossless=True,\n",
    "    debug=False,\n",
    ") as camera:\n",
    "    camera.start()\n",
    "    try:\n",
    "        while True:\n",
    "            image = camera.get_array()\n",
    "            # split the image into 4 quadrants\n",
    "            image = image.reshape(1, WIDTH, HEIGHT, 1)\n",
    "            image = np.concatenate([image[:, :WIDTH//2, :HEIGHT//2], image[:, WIDTH//2:, :HEIGHT//2], image[:, :WIDTH//2, HEIGHT//2:], image[:, WIDTH//2:, HEIGHT//2:]], axis=0)\n",
    "            # put the image on the gpu\n",
    "            image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "            # repeat the image to match the batch size\n",
    "            # pass the image through the model\n",
    "            if BATCH_SIZE > 1:\n",
    "                image = tf.repeat(image, BATCH_SIZE, axis=0)\n",
    "            predictions = model.predict(image, verbose=0)\n",
    "            # track frame rate\n",
    "            current_time = time.perf_counter()\n",
    "            frame_rate = 1 / (current_time - previous_time)\n",
    "            previous_time = current_time\n",
    "            fps.append(frame_rate)\n",
    "            if current_time - last_display > update_period:\n",
    "                last_display = current_time\n",
    "                # update the plot\n",
    "                line1.set_xdata(range(len(fps)))\n",
    "                line1.set_ydata(fps)\n",
    "                ax.relim()\n",
    "                ax.autoscale_view()\n",
    "                fig.canvas.draw()\n",
    "                fig.canvas.flush_events()\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        # get stack trace and save to file\n",
    "        with open(\"error.txt\", \"w\") as f:\n",
    "            f.write(str(e))\n",
    "            f.write(\"\\n\")\n",
    "            f.write(str(sys.exc_info()))\n",
    "            f.write(\"\\n\")\n",
    "            f.write(traceback.format_exc())\n",
    "    # save the data\n",
    "    np.save(\"fps.npy\", fps)\n",
    "    camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7eb2e80e4250>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
